import os
import re
import time
import struct
from collections import defaultdict

def analyze_dump(dump_path):
    """
    –£–ª—É—á—à–µ–Ω–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –¥–∞–º–ø–∞ –ø–∞–º—è—Ç–∏ - –∏—â–µ—Ç —Ä–µ–∞–ª—å–Ω—ã–µ —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö
    """
    print(f"üöÄ Starting enhanced analysis of: {dump_path}")
    result = {
        'os_info': {},
        'processes': [],
        'network_connections': [],
        'strings_found': [],
        'status': 'completed',
        'analysis_time': time.strftime('%Y-%m-%d %H:%M:%S'),
        'file_size_gb': os.path.getsize(dump_path) / (1024**3)
    }
    
    try:
        file_size = os.path.getsize(dump_path)
        print(f"üìä File size: {file_size/(1024*1024*1024):.2f} GB")
        
        # –ê–Ω–∞–ª–∏–∑–∏—Ä—É–µ–º —Ä–∞–∑–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∞–π–ª–∞
        with open(dump_path, 'rb') as f:
            # 1. –ê–Ω–∞–ª–∏–∑ —è–¥—Ä–∞ Linux (–ø–µ—Ä–≤—ã–µ 2MB)
            print("üîç Analyzing kernel structures...")
            kernel_data = f.read(2 * 1024 * 1024)  # 2MB
            result['os_info'] = extract_linux_info(kernel_data)
            
            # 2. –ü–æ–∏—Å–∫ —Å—Ç—Ä–æ–∫ throughout —Ñ–∞–π–ª–∞
            print("üîç Searching for readable strings...")
            f.seek(0)
            result['strings_found'] = find_meaningful_strings(f, file_size)
            
            # 3. –ü–æ–∏—Å–∫ —Å–µ—Ç–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
            print("üåê Searching for network information...")
            f.seek(0)
            result['network_connections'] = find_network_info(f, file_size)
            
            # 4. –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö
            print("üìã Searching for process information...")
            f.seek(0)
            result['processes'] = find_process_info(f, file_size)
            
        print(f"‚úÖ Enhanced analysis completed")
        
    except Exception as e:
        print(f"‚ùå Error analyzing dump: {e}")
        import traceback
        traceback.print_exc()
        result['error'] = str(e)
        result['status'] = 'error'
    
    return result

def extract_linux_info(data):
    """–ò–∑–≤–ª–µ–∫–∞–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ Linux —Å–∏—Å—Ç–µ–º–µ"""
    info = {}
    
    # –ü–æ–∏—Å–∫ –≤–µ—Ä—Å–∏–∏ —è–¥—Ä–∞ Linux (–±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω—ã–µ –ø–∞—Ç—Ç–µ—Ä–Ω—ã)
    kernel_patterns = [
        rb'Linux version (\d+\.\d+\.\d+[-\w+]*)',
        rb'#(\d+)-[A-Za-z]+\s+SMP',
        rb'SMP.*?(\d+\.\d+\.\d+[-\w+]*)',
        rb'PREEMPT.*?(\d+\.\d+\.\d+[-\w+]*)'
    ]
    
    for pattern in kernel_patterns:
        match = re.search(pattern, data, re.IGNORECASE)
        if match:
            try:
                info['kernel_version'] = match.group(1).decode('utf-8', errors='ignore')
                print(f"   ‚úÖ Found kernel: {info['kernel_version']}")
                break
            except:
                continue
    
    # –ü–æ–∏—Å–∫ –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—ã
    arch_patterns = {
        'x86_64': [rb'x86_64', rb'AMD64', rb'lmae'],
        'i386': [rb'i386', rb'i686', rb'x86'],
        'arm': [rb'ARM', rb'armv', rb'aarch'],
        'aarch64': [rb'aarch64', rb'arm64']
    }
    
    for arch, patterns in arch_patterns.items():
        for pattern in patterns:
            if re.search(pattern, data, re.IGNORECASE):
                info['architecture'] = arch
                print(f"   ‚úÖ Found architecture: {arch}")
                break
        if 'architecture' in info:
            break
    
    # –ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –¥–∏—Å—Ç—Ä–∏–±—É—Ç–∏–≤–µ
    distro_patterns = [
        (rb'Ubuntu', 'Ubuntu'),
        (rb'Debian', 'Debian'),
        (rb'CentOS', 'CentOS'),
        (rb'Red Hat', 'Red Hat'),
        (rb'Fedora', 'Fedora'),
        (rb'SUSE', 'SUSE'),
        (rb'Gentoo', 'Gentoo'),
        (rb'Arch Linux', 'Arch')
    ]
    
    for pattern, distro in distro_patterns:
        if re.search(pattern, data, re.IGNORECASE):
            info['distribution'] = distro
            print(f"   ‚úÖ Found distribution: {distro}")
            break
    
    return info

def find_meaningful_strings(f, file_size):
    """–ü–æ–∏—Å–∫ –æ—Å–º—ã—Å–ª–µ–Ω–Ω—ã—Ö —Å—Ç—Ä–æ–∫ –≤ –¥–∞–º–ø–µ"""
    strings = []
    string_pattern = rb'[\\x20-\\x7E]{8,500}'  # –ë–æ–ª–µ–µ –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –ø–æ–∑–∏—Ü–∏–∏ –≤ —Ñ–∞–π–ª–µ
    sample_positions = [
        0,                          # –ù–∞—á–∞–ª–æ (—è–¥—Ä–æ)
        file_size // 8,             # 12.5%
        file_size // 4,             # 25%
        file_size // 2,             # 50%
        file_size * 3 // 4,         # 75%
        file_size - (2 * 1024 * 1024)  # –ö–æ–Ω–µ—Ü (—Å—Ç–µ–∫/–∫—É—á–∞)
    ]
    
    meaningful_keywords = [
        'linux', 'ubuntu', 'debian', 'centos', 'redhat', 'fedora',
        'http://', 'https://', 'tcp', 'udp', 'ssh', 'bash', 'python',
        'mysql', 'apache', 'nginx', 'docker', 'kube', 'systemd',
        'root', 'home', 'etc/', 'var/', 'proc/', 'sys/', 'dev/'
    ]
    
    for pos in sample_positions:
        if pos < file_size:
            f.seek(pos)
            data = f.read(65536)  # 64KB —á–∞–Ω–∫–∏
            
            matches = re.finditer(string_pattern, data)
            for match in matches:
                try:
                    string = match.group(0).decode('utf-8', errors='ignore')
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –æ—Å–º—ã—Å–ª–µ–Ω–Ω–æ—Å—Ç—å
                    if (len(string) >= 10 and 
                        any(keyword in string.lower() for keyword in meaningful_keywords) and
                        not string.isdigit()):
                        
                        strings.append({
                            'string': string[:200],  # –û–±—Ä–µ–∑–∞–µ–º –¥–ª–∏–Ω–Ω—ã–µ —Å—Ç—Ä–æ–∫–∏
                            'offset': pos + match.start(),
                            'context': 'memory_dump'
                        })
                        
                except:
                    continue
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã –∏ –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ
    unique_strings = []
    seen_strings = set()
    
    for s in strings:
        if s['string'] not in seen_strings:
            unique_strings.append(s)
            seen_strings.add(s['string'])
    
    return unique_strings[:50]

def find_network_info(f, file_size):
    """–ü–æ–∏—Å–∫ —Å–µ—Ç–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏"""
    connections = []
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è —Å–µ—Ç–µ–≤–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏
    ip_pattern = rb'\b(?:\d{1,3}\.){3}\d{1,3}\b'
    mac_pattern = rb'\b(?:[0-9A-Fa-f]{2}:){5}[0-9A-Fa-f]{2}\b'
    url_pattern = rb'https?://[^\s<>"{}|\\^`\[\]]+'
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ä–∞–∑–Ω—ã–µ –æ–±–ª–∞—Å—Ç–∏ —Ñ–∞–π–ª–∞
    sample_positions = [
        0,
        file_size // 4,
        file_size // 2,
        file_size * 3 // 4
    ]
    
    for pos in sample_positions:
        if pos < file_size:
            f.seek(pos)
            data = f.read(131072)  # 128KB
            
            # IP –∞–¥—Ä–µ—Å–∞
            ip_matches = re.finditer(ip_pattern, data)
            for match in ip_matches:
                try:
                    ip = match.group(0).decode('utf-8')
                    if all(0 <= int(part) <= 255 for part in ip.split('.')):
                        connections.append({
                            'type': 'ip_address',
                            'value': ip,
                            'offset': pos + match.start()
                        })
                except:
                    continue
            
            # MAC –∞–¥—Ä–µ—Å–∞
            mac_matches = re.finditer(mac_pattern, data, re.IGNORECASE)
            for match in mac_matches:
                try:
                    mac = match.group(0).decode('utf-8')
                    connections.append({
                        'type': 'mac_address',
                        'value': mac,
                        'offset': pos + match.start()
                    })
                except:
                    continue
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_connections = []
    seen_values = set()
    
    for conn in connections:
        if conn['value'] not in seen_values:
            unique_connections.append(conn)
            seen_values.add(conn['value'])
    
    return unique_connections[:30]

def find_process_info(f, file_size):
    """–ü–æ–∏—Å–∫ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ—Ü–µ—Å—Å–∞—Ö"""
    processes = []
    
    # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤ –∏ –ø—É—Ç–µ–π
    process_patterns = [
        rb'/proc/\d+',
        rb'/bin/[a-zA-Z0-9_\-]+',
        rb'/usr/bin/[a-zA-Z0-9_\-]+',
        rb'/sbin/[a-zA-Z0-9_\-]+',
        rb'/usr/sbin/[a-zA-Z0-9_\-]+',
        rb'[a-zA-Z0-9_\-]+\.sh\b',
        rb'python\d?\.?\d?',
        rb'bash|zsh|sh|dash',
        rb'sshd|nginx|apache|mysql|postgres',
        rb'docker|kube|containerd'
    ]
    
    # –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –¥–ª—è –ø—Ä–æ—Ü–µ—Å—Å–æ–≤
    process_keywords = [
        'pid', 'ppid', 'comm', 'task_struct', 'process',
        'thread', 'exec', 'fork', 'clone'
    ]
    
    sample_positions = [
        file_size // 8,
        file_size // 4,
        file_size // 2,
        file_size * 3 // 4
    ]
    
    for pos in sample_positions:
        if pos < file_size:
            f.seek(pos)
            data = f.read(65536)
            
            for pattern in process_patterns:
                matches = re.finditer(pattern, data, re.IGNORECASE)
                for match in matches:
                    try:
                        process_str = match.group(0).decode('utf-8', errors='ignore')
                        if (len(process_str) >= 4 and 
                            not process_str.isdigit() and
                            any(keyword in process_str.lower() for keyword in process_keywords)):
                            
                            processes.append({
                                'name': process_str[:100],
                                'type': 'process_reference',
                                'offset': pos + match.start()
                            })
                    except:
                        continue
    
    # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏–∫–∞—Ç—ã
    unique_processes = []
    seen_names = set()
    
    for proc in processes:
        if proc['name'] not in seen_names:
            unique_processes.append(proc)
            seen_names.add(proc['name'])
    
    return unique_processes[:20]

# –î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª–∏–∑–∞
def detailed_analysis(dump_path):
    """–ë–æ–ª–µ–µ –¥–µ—Ç–∞–ª—å–Ω—ã–π –∞–Ω–∞–ª–∏–∑ –¥–ª—è –±–æ–ª—å—à–∏—Ö –¥–∞–º–ø–æ–≤"""
    print(f"üîç Starting detailed analysis of: {dump_path}")
    
    results = {
        'sections': [],
        'potential_artifacts': []
    }
    
    # –ó–¥–µ—Å—å –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –±–æ–ª–µ–µ —Å–ª–æ–∂–Ω—ã–π –∞–Ω–∞–ª–∏–∑
    
    return results